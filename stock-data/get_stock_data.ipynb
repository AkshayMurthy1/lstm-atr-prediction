{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775d4daa",
   "metadata": {},
   "source": [
    "# Retrieve Stock Data and Save to DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fed49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "05151c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_stock(ticker, start_date, end_date, s_window, l_window):\n",
    "    try:\n",
    "        #yf.pdr_override()\n",
    "        df = yf.download(ticker, start=start_date, end=end_date,auto_adjust=False)\n",
    "        #print(\"DF: \",df)\n",
    "# can use this as well        df = web.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "        df['Return'] = df['Adj Close'].pct_change()\n",
    "        df['Return'].fillna(0, inplace = True)\n",
    "        df['Date'] = df.index\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['Year'] = df['Date'].dt.year \n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Adj Close']:\n",
    "            df[col] = df[col].round(2)\n",
    "        df['Weekday'] = df['Date'].dt.day_name()\n",
    "        df['Week_Number'] = df['Date'].dt.strftime('%U')\n",
    "        df['Year_Week'] = df['Date'].dt.strftime('%Y-%U')\n",
    "        df['Short_MA'] = df['Adj Close'].rolling(window=s_window, min_periods=1).mean()\n",
    "        df['Long_MA'] = df['Adj Close'].rolling(window=l_window, min_periods=1).mean()        \n",
    "        col_list = ['Date', 'Year', 'Month', 'Day', 'Weekday', \n",
    "                    'Week_Number', 'Year_Week', 'Open', \n",
    "                    'High', 'Low', 'Close', 'Volume', 'Adj Close',\n",
    "                    'Return', 'Short_MA', 'Long_MA']\n",
    "        num_lines = len(df)\n",
    "        df = df[col_list]\n",
    "        print('read ', num_lines, ' lines of data for ticker: ' , ticker)\n",
    "        return df\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d79bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read  6415  lines of data for ticker:  SPY\n",
      "wrote 6415 lines to file: /Users/jonathanyan/Desktop/RISE DS/DS-Prac/Stock_market_proj/lstm-atr-prediction/stock-data/SPY.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1516439336.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Return'].fillna(0, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ticker='SPY'\n",
    "    input_dir = os.getcwd()\n",
    "    output_file = os.path.join(input_dir, ticker + '.csv')\n",
    "    df = get_stock(ticker, start_date='2000-01-01', end_date='2025-07-08', \n",
    "               s_window=14, l_window=50)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print('wrote ' + str(len(df)) + ' lines to file: ' + output_file)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('failed to get Yahoo stock data for ticker: ', ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "79956dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. create ATR column\\n2. create SD column\\n3. build LSTM columnn\\n4. split into train and test\\n5. train lstm on training data for ATR and test\\n6. train lstm on training data for SD and test\\n7. plot results and avg. returns based on decisions (buy if delta_volatility<-alpha, sell if delta_volatility>alpha)\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#psuedocode\n",
    "'''\n",
    "1. create ATR column\n",
    "2. create SD column\n",
    "3. build LSTM columnn\n",
    "4. split into train and test\n",
    "5. train lstm on training data for ATR and test\n",
    "6. train lstm on training data for SD and test\n",
    "7. plot results and avg. returns based on decisions (buy if delta_volatility<-alpha, sell if delta_volatility>alpha)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a91feef9",
   "metadata": {},
   "outputs": [],
   "source": [
    " #.xs returns a cross section; selects only values within the SPY indexes at level=1\n",
    "df_n= df.xs('SPY',axis=1,level=1)\n",
    "#cleaned up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d501d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# #challenge of how to deal with missing values in time series data\n",
    "# #choose sliding window of length=N (could be 20?) N_lstmtraining>N_atrslidingwindow\n",
    "# def atr_func(d):\n",
    "#     running = 0\n",
    "#     for i in range(len(d)):\n",
    "#         high = d.loc[i,\"High\"]\n",
    "#         low = d.loc[i,\"Low\"]\n",
    "#         if i==0:\n",
    "#             running += high-low\n",
    "#             continue\n",
    "#         if i>0:\n",
    "#             y_close = d.loc[i,\"Close\"]\n",
    "        \n",
    "#         TR = max(high-low,max(math.abs(high-y_close),math.abs(low-y_close)))\n",
    "#         running+=TR\n",
    "#     return running/len(d)\n",
    "\n",
    "# df_n['ATR'] = df_n.rolling(window=14).apply(atr_func)\n",
    "# df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5c5bb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/4206602609.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n[\"ATR\"] = tr.rolling(7).mean()\n"
     ]
    }
   ],
   "source": [
    "#define ATR columns\n",
    "high = df_n[\"High\"]\n",
    "low = df_n[\"Low\"]\n",
    "close = df_n[\"Close\"]\n",
    "\n",
    "prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "tr = pd.concat([\n",
    "    high - low,\n",
    "    (high - prev_close).abs(),\n",
    "    (low - prev_close).abs()\n",
    "], axis=1).max(axis=1)\n",
    "\n",
    "df_n[\"ATR\"] = tr.rolling(7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aca5313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1671279891.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1671279891.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1671279891.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ATR</th>\n",
       "      <th>SD_Log_Close</th>\n",
       "      <th>ATR_normalized</th>\n",
       "      <th>SD_normalized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>148.25</td>\n",
       "      <td>148.25</td>\n",
       "      <td>143.88</td>\n",
       "      <td>145.44</td>\n",
       "      <td>8164300</td>\n",
       "      <td>92.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>143.53</td>\n",
       "      <td>144.06</td>\n",
       "      <td>139.64</td>\n",
       "      <td>139.75</td>\n",
       "      <td>8089800</td>\n",
       "      <td>88.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>139.94</td>\n",
       "      <td>141.53</td>\n",
       "      <td>137.25</td>\n",
       "      <td>140.00</td>\n",
       "      <td>12177900</td>\n",
       "      <td>88.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>139.62</td>\n",
       "      <td>141.50</td>\n",
       "      <td>137.75</td>\n",
       "      <td>137.75</td>\n",
       "      <td>6227200</td>\n",
       "      <td>87.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>140.31</td>\n",
       "      <td>145.75</td>\n",
       "      <td>140.06</td>\n",
       "      <td>145.75</td>\n",
       "      <td>8066500</td>\n",
       "      <td>92.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>5.868571</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.151276</td>\n",
       "      <td>-0.589089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>5.398571</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>-0.766251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02</th>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>4.717143</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>-0.825029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03</th>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.591007</td>\n",
       "      <td>-0.921698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-07</th>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>5.078571</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.839263</td>\n",
       "      <td>-0.621569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6415 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price         Open    High     Low   Close    Volume  Adj Close       ATR  \\\n",
       "Date                                                                        \n",
       "2000-01-03  148.25  148.25  143.88  145.44   8164300      92.14       NaN   \n",
       "2000-01-04  143.53  144.06  139.64  139.75   8089800      88.54       NaN   \n",
       "2000-01-05  139.94  141.53  137.25  140.00  12177900      88.70       NaN   \n",
       "2000-01-06  139.62  141.50  137.75  137.75   6227200      87.27       NaN   \n",
       "2000-01-07  140.31  145.75  140.06  145.75   8066500      92.34       NaN   \n",
       "...            ...     ...     ...     ...       ...        ...       ...   \n",
       "2025-06-30  617.38  619.22  615.04  617.85  92502500     617.85  5.868571   \n",
       "2025-07-01  616.36  618.83  615.52  617.65  70030100     617.65  5.398571   \n",
       "2025-07-02  617.24  620.49  616.61  620.45  66510400     620.45  4.717143   \n",
       "2025-07-03  622.45  626.28  622.43  625.34  51065800     625.34  4.450000   \n",
       "2025-07-07  623.36  624.03  617.87  620.68  74814500     620.68  5.078571   \n",
       "\n",
       "Price       SD_Log_Close  ATR_normalized  SD_normalized  \n",
       "Date                                                     \n",
       "2000-01-03           NaN             NaN            NaN  \n",
       "2000-01-04           NaN             NaN            NaN  \n",
       "2000-01-05           NaN             NaN            NaN  \n",
       "2000-01-06           NaN             NaN            NaN  \n",
       "2000-01-07           NaN             NaN            NaN  \n",
       "...                  ...             ...            ...  \n",
       "2025-06-30      0.005666        1.151276      -0.589089  \n",
       "2025-07-01      0.004345        0.965648      -0.766251  \n",
       "2025-07-02      0.003906        0.696516      -0.825029  \n",
       "2025-07-03      0.003185        0.591007      -0.921698  \n",
       "2025-07-07      0.005424        0.839263      -0.621569  \n",
       "\n",
       "[6415 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "#xlb, xle, \n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "826b5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1641309427.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['atr_slope_7'] = df_n['ATR'].rolling(window=7).apply(slope, raw=True)\n",
      "/var/folders/q9/9j4tq0z16h37tyl8y408ycs40000gn/T/ipykernel_62505/1641309427.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_n['stock_slope'] = df_n['Open'].rolling(window=7).apply(slope, raw=True)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "\n",
    "def slope(x):\n",
    "    idx = np.arange(len(x))\n",
    "    return linregress(idx, x).slope\n",
    "\n",
    "df_n['atr_slope_7'] = df_n['ATR'].rolling(window=7).apply(slope, raw=True)\n",
    "df_n['stock_slope'] = df_n['Open'].rolling(window=7).apply(slope, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9a6eb499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na values (first 6 rows)\n",
    "df_n = df_n.dropna()\n",
    "df_n = df_n.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1dbb254",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'index'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_n[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_n\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m7\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'index'"
     ]
    }
   ],
   "source": [
    "df_n[\"index\"] = df_n[\"index\"]%7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ATR</th>\n",
       "      <th>SD_Log_Close</th>\n",
       "      <th>ATR_normalized</th>\n",
       "      <th>SD_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>144.59</td>\n",
       "      <td>144.59</td>\n",
       "      <td>142.88</td>\n",
       "      <td>143.06</td>\n",
       "      <td>6907700</td>\n",
       "      <td>90.64</td>\n",
       "      <td>4.024286</td>\n",
       "      <td>0.029618</td>\n",
       "      <td>0.422870</td>\n",
       "      <td>2.622685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>144.47</td>\n",
       "      <td>145.75</td>\n",
       "      <td>143.28</td>\n",
       "      <td>145.00</td>\n",
       "      <td>5158300</td>\n",
       "      <td>91.87</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.247398</td>\n",
       "      <td>1.979539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>146.53</td>\n",
       "      <td>147.47</td>\n",
       "      <td>145.97</td>\n",
       "      <td>146.97</td>\n",
       "      <td>7437300</td>\n",
       "      <td>93.11</td>\n",
       "      <td>3.321429</td>\n",
       "      <td>0.024942</td>\n",
       "      <td>0.145274</td>\n",
       "      <td>1.995695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>145.34</td>\n",
       "      <td>146.62</td>\n",
       "      <td>145.19</td>\n",
       "      <td>145.81</td>\n",
       "      <td>6488500</td>\n",
       "      <td>92.38</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>1.847051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>145.31</td>\n",
       "      <td>147.00</td>\n",
       "      <td>145.00</td>\n",
       "      <td>147.00</td>\n",
       "      <td>6157900</td>\n",
       "      <td>93.13</td>\n",
       "      <td>2.182857</td>\n",
       "      <td>0.011098</td>\n",
       "      <td>-0.304408</td>\n",
       "      <td>0.139264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>5.868571</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.151276</td>\n",
       "      <td>-0.589089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>5.398571</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>-0.766251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>4.717143</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>-0.825029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.591007</td>\n",
       "      <td>-0.921698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>5.078571</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.839263</td>\n",
       "      <td>-0.621569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6408 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date    Open    High     Low   Close    Volume  Adj Close  \\\n",
       "0     2000-01-12  144.59  144.59  142.88  143.06   6907700      90.64   \n",
       "1     2000-01-13  144.47  145.75  143.28  145.00   5158300      91.87   \n",
       "2     2000-01-14  146.53  147.47  145.97  146.97   7437300      93.11   \n",
       "3     2000-01-18  145.34  146.62  145.19  145.81   6488500      92.38   \n",
       "4     2000-01-19  145.31  147.00  145.00  147.00   6157900      93.13   \n",
       "...          ...     ...     ...     ...     ...       ...        ...   \n",
       "6403  2025-06-30  617.38  619.22  615.04  617.85  92502500     617.85   \n",
       "6404  2025-07-01  616.36  618.83  615.52  617.65  70030100     617.65   \n",
       "6405  2025-07-02  617.24  620.49  616.61  620.45  66510400     620.45   \n",
       "6406  2025-07-03  622.45  626.28  622.43  625.34  51065800     625.34   \n",
       "6407  2025-07-07  623.36  624.03  617.87  620.68  74814500     620.68   \n",
       "\n",
       "Price       ATR  SD_Log_Close  ATR_normalized  SD_normalized  \n",
       "0      4.024286      0.029618        0.422870       2.622685  \n",
       "1      3.580000      0.024822        0.247398       1.979539  \n",
       "2      3.321429      0.024942        0.145274       1.995695  \n",
       "3      3.040000      0.023834        0.034123       1.847051  \n",
       "4      2.182857      0.011098       -0.304408       0.139264  \n",
       "...         ...           ...             ...            ...  \n",
       "6403   5.868571      0.005666        1.151276      -0.589089  \n",
       "6404   5.398571      0.004345        0.965648      -0.766251  \n",
       "6405   4.717143      0.003906        0.696516      -0.825029  \n",
       "6406   4.450000      0.003185        0.591007      -0.921698  \n",
       "6407   5.078571      0.005424        0.839263      -0.621569  \n",
       "\n",
       "[6408 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_n[\"Delta_Days\"] = [(df_n.loc[i,\"Date\"] - df_n.loc[0,\"Date\"]).days for i in range(len(df_n))]\n",
    "# #save clean data\n",
    "# df_n.to_csv(\"Clean_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lstm model\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN_LSTM(Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size,hidden_size=30)\n",
    "        self.fc = Linear(30,output_size)\n",
    "    def activation(self,X):\n",
    "        return F.relu(X)\n",
    "    def forward(self,input):\n",
    "        input,_ = self.lstm(input)\n",
    "        input = self.fc(input[-1,:,:])\n",
    "        return input #return the last prediction\n",
    "#lstm_layer = LSTM(input_size=4,hidden_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a557c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define PDE loss\n",
    "def PDE_loss(v_hat,):\n",
    "    return 0\n",
    "    #use torch.autograd to get PDE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9134de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbb3ba9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['index'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     y_test \u001b[38;5;241m=\u001b[39m test[vol_metric]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_train,y_train,X_test,y_test\n\u001b[0;32m---> 11\u001b[0m X_train,y_train,X_test,y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtt_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_n\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mATR_normalized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#bollinger bands\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#try moving median instead of moving average\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#try moving quartiles instead of std; q3-q2  *1/2\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#take longer time period - five years\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#lstm,cnn,and rnn cant either predict directional volatiliy for xl stocks\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m, in \u001b[0;36mtt_split\u001b[0;34m(df_n, vol_metric)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtt_split\u001b[39m(df_n,vol_metric):\n\u001b[1;32m      2\u001b[0m     train \u001b[38;5;241m=\u001b[39m df_n\u001b[38;5;241m.\u001b[39mloc[[i\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_n)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_n))]]\n\u001b[0;32m----> 3\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOpen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHigh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvol_metric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      4\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m train[vol_metric]\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      6\u001b[0m     test \u001b[38;5;241m=\u001b[39m df_n\u001b[38;5;241m.\u001b[39mloc[[i\u001b[38;5;241m>\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_n)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df_n))]]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4112\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4113\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4115\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:6212\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6209\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6210\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6212\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6214\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6216\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/core/indexes/base.py:6264\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6263\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['index'] not in index\""
     ]
    }
   ],
   "source": [
    "def tt_split(df_n,vol_metric):\n",
    "    train = df_n.loc[[i<=len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_train = train[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_train = train[vol_metric].to_numpy()\n",
    "\n",
    "    test = df_n.loc[[i>len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_test = test[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_test = test[vol_metric].to_numpy()\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "X_train,y_train,X_test,y_test = tt_split(df_n,\"ATR_normalized\")\n",
    "\n",
    "#bollinger bands\n",
    "#try moving median instead of moving average\n",
    "#try moving quartiles instead of std; q3-q2  *1/2\n",
    "#take longer time period - five years\n",
    "\n",
    "#lstm,cnn,and rnn cant either predict directional volatiliy for xl stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76390f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(X_train,y_train,X_test,y_test):\n",
    "    T = 30  # sequence length (window size)\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    X_seq_test = []\n",
    "    y_seq_test = []\n",
    "\n",
    "    for i in range(len(X_train) - T):\n",
    "        X_seq.append(X_train[i:i+T])  # shape: [T, 6] <- what is wanted in lstm\n",
    "        y_seq.append(y_train[i+T])    # predict next ATR value\n",
    "    for i in range(len(X_test)-T):    \n",
    "        X_seq_test.append(X_test[i:i+T])\n",
    "        y_seq_test.append(y_test[i+T])\n",
    "\n",
    "\n",
    "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "    y_seq = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
    "    X_seq_test = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "    y_seq_test = torch.tensor(y_seq_test, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return X_seq,y_seq,X_seq_test,y_seq_test\n",
    "X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_loaders(X_seq,y_seq,X_seq_test,y_seq_test,batch_size=64):\n",
    "    dataset = TensorDataset(X_seq, y_seq)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(X_seq_test,y_seq_test)\n",
    "    loader_test = DataLoader(dataset_test,batch_size=batch_size,shuffle=True)\n",
    "    return loader,loader_test\n",
    "loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training loop\n",
    "# model = NN_LSTM(input_size=5,output_size=1)\n",
    "# epochs = 100\n",
    "# optim = torch.optim.Adam(params = model.parameters())\n",
    "# crit = MSELoss()\n",
    "# losses = []\n",
    "# losses_test = []\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for x_window,y_atr in loader:\n",
    "#         #print(\"Running\")\n",
    "#         input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "#         out = model(input)\n",
    "#         #print(y_atr.shape)\n",
    "#         #print(out,y_atr)\n",
    "#         #break\n",
    "#         loss = crit(out,y_atr)\n",
    "#         running_loss+=loss.item()\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#             # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "#     #break\n",
    "#     running_loss/=(len(loader))\n",
    "#     #print(f\"Training Loss: {running_loss}\")\n",
    "#     losses.append(running_loss)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         testing_loss = 0\n",
    "#         for x_window_test,y_atr_test in loader_test:\n",
    "#             out_test = model(x_window_test.permute(1,0,2))\n",
    "#             #print(y_atr_test.shape)\n",
    "#             loss = crit(out_test,y_atr_test)\n",
    "#             testing_loss+=loss.item()\n",
    "#         losses_test.append(testing_loss/(len(loader_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "# plt.title(\"Training Loss of LSTM (ATR_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses_test)\n",
    "# plt.title(\"Testing Loss of LSTM (ATR_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21004adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sd,y_train_sd,X_test_sd,y_test_sd = tt_split(df_n,vol_metric=\"SD_normalized\")\n",
    "# X_seq_sd,y_seq_sd,X_seq_test_sd,y_seq_test_sd = make_seq(X_train_sd,y_train_sd,X_test_sd,y_test_sd)\n",
    "# loader_sd,loader_test_sd = create_loaders(X_seq_sd,y_seq_sd,X_seq_test_sd,y_seq_test_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7127c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training loop\n",
    "# model_sd = NN_LSTM(input_size=5,output_size=1)\n",
    "# epochs = 100\n",
    "# optim = torch.optim.Adam(params = model_sd.parameters())\n",
    "# crit = MSELoss()\n",
    "# losses = []\n",
    "# losses_test = []\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for x_window,y_sd in loader_sd:\n",
    "#         #print(\"Running\")\n",
    "#         input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "#         out = model_sd(input)\n",
    "#         #print(y_sd.shape)\n",
    "#         loss = crit(out,y_sd)\n",
    "#         running_loss+=loss.item()\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#             # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "#     running_loss/=(len(loader_sd))\n",
    "#     #print(f\"Training Loss: {running_loss}\")\n",
    "#     losses.append(running_loss)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         testing_loss = 0\n",
    "#         for x_window_test,y_sd_test in loader_test_sd:\n",
    "#             out_test = model_sd(x_window_test.permute(1,0,2))\n",
    "#             #print(y_sd_test.shape)\n",
    "#             loss = crit(out_test,y_sd_test)\n",
    "#             testing_loss+=loss.item()\n",
    "#         losses_test.append(testing_loss/(len(loader_test_sd)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f08d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses)\n",
    "# plt.title(\"Training Loss of LSTM (SD__normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses_test)\n",
    "# plt.title(\"Testing Loss of LSTM (SD_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use past atrs\n",
    "#try transformations of atr log(atr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f219ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(ticker,start,end,metric):\n",
    "    df = get_stock(ticker,start_date=start,end_date=end,s_window=14,l_window=50)\n",
    "    df_n= df.xs(ticker,axis=1,level=1)\n",
    "    \n",
    "        #define ATR columns\n",
    "    high = df_n[\"High\"]\n",
    "    low = df_n[\"Low\"]\n",
    "    close = df_n[\"Close\"]\n",
    "\n",
    "    prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - prev_close).abs(),\n",
    "        (low - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    df_n[\"ATR\"] = tr.rolling(7).mean()\n",
    "    \n",
    "    log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "    df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "    df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "    df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "\n",
    "    df_n = df_n.dropna()\n",
    "    df_n = df_n.reset_index()\n",
    "    df_n[\"index\"] = df_n.index%7 \n",
    "    print(df_n)\n",
    "\n",
    "    X_train,y_train,X_test,y_test = tt_split(df_n, metric)\n",
    "\n",
    "    X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)\n",
    "\n",
    "    loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)\n",
    "\n",
    "    #training loop\n",
    "    \n",
    "    model = NN_LSTM(input_size=6,output_size=1)\n",
    "    epochs = 100\n",
    "    optim = torch.optim.Adam(params = model.parameters())\n",
    "    crit = MSELoss()\n",
    "    losses = []\n",
    "    losses_test = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for x_window,y_atr in loader:\n",
    "            #print(\"Running\")\n",
    "            input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "            out = model(input)\n",
    "            #print(y_atr.shape)\n",
    "            #print(out,y_atr)\n",
    "            #break\n",
    "            loss = crit(out,y_atr)\n",
    "            running_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "                # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "        #break\n",
    "        running_loss/=(len(loader))\n",
    "        #print(f\"Training Loss: {running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            testing_loss = 0\n",
    "            for x_window_test,y_atr_test in loader_test:\n",
    "                out_test = model(x_window_test.permute(1,0,2))\n",
    "                #print(y_atr_test.shape)\n",
    "                loss = crit(out_test,y_atr_test)\n",
    "                testing_loss+=loss.item()\n",
    "            losses_test.append(testing_loss/(len(loader_test)))\n",
    "\n",
    "    sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "    plt.title(f\"Training Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.lineplot(losses_test)\n",
    "    plt.title(f\"Testing Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    return min(losses),min(losses_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8faf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2000-01-01\"\n",
    "end = \"2025-07-14\"\n",
    "#pipeline(\"SPY\",start,end,metric=\"ATR_normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c59dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline(\"XLP\",start,end,metric=\"SD_normalized\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6154311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fc6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read  6419  lines of data for ticker:  XLB\n",
      "Price       Date   Open   High    Low  Close   Volume  Adj Close       ATR  \\\n",
      "0     2000-01-12  26.61  27.03  26.61  26.64   135300      15.04  0.640000   \n",
      "1     2000-01-13  26.89  26.97  26.62  26.75    45900      15.11  0.627143   \n",
      "2     2000-01-14  26.52  26.72  26.44  26.56    76000      15.00  0.515714   \n",
      "3     2000-01-18  26.22  26.31  25.69  25.92    34400      14.64  0.504286   \n",
      "4     2000-01-19  25.78  25.95  25.42  25.42   125700      14.36  0.510000   \n",
      "...          ...    ...    ...    ...    ...      ...        ...       ...   \n",
      "6407  2025-07-07  90.90  91.22  90.01  90.49  5880800      90.49  1.254286   \n",
      "6408  2025-07-08  90.68  91.52  90.57  91.23  8173800      91.23  1.224286   \n",
      "6409  2025-07-09  91.47  91.88  90.92  91.78  6717800      91.78  1.235714   \n",
      "6410  2025-07-10  92.00  92.86  91.81  92.27  6432800      92.27  1.297143   \n",
      "6411  2025-07-11  91.28  91.68  90.81  91.52  5781600      91.52  1.108571   \n",
      "\n",
      "Price  SD_Log_Close  ATR_normalized  SD_normalized  index  \n",
      "0          0.021011       -0.337562       1.019430      0  \n",
      "1          0.020186       -0.364605       0.916591      1  \n",
      "2          0.013385       -0.598982       0.069896      2  \n",
      "3          0.009580       -0.623021      -0.403946      3  \n",
      "4          0.009731       -0.611001      -0.385123      4  \n",
      "...             ...             ...            ...    ...  \n",
      "6407       0.011869        0.954516      -0.118919      2  \n",
      "6408       0.011713        0.891415      -0.138294      3  \n",
      "6409       0.011562        0.915453      -0.157092      4  \n",
      "6410       0.011158        1.044661      -0.207498      5  \n",
      "6411       0.008915        0.648023      -0.486718      6  \n",
      "\n",
      "[6412 rows x 12 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "etfs = ['XLB','XLE','XLF','XLI','XLP','XLV','XLY','XLU']\n",
    "metrics = [\"ATR_normalized\",\"SD_normalized\"]\n",
    "df = pd.DataFrame({\"etf\":[],\"metric\":[],\"train_loss\":[],\"test_loss\":[]})\n",
    "for etf in etfs[:2]:\n",
    "    for metric in metrics:\n",
    "        train_loss_atr, test_loss_atr = pipeline(etf,start,end,metric=metric)\n",
    "        df.loc[len(df)] = [etf,metric,train_loss_atr,test_loss_atr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44015da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Week_Number</th>\n",
       "      <th>Year_Week</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Return</th>\n",
       "      <th>Short_MA</th>\n",
       "      <th>Long_MA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Monday</td>\n",
       "      <td>01</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>148.25</td>\n",
       "      <td>148.25</td>\n",
       "      <td>143.88</td>\n",
       "      <td>145.44</td>\n",
       "      <td>8164300</td>\n",
       "      <td>92.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92.140000</td>\n",
       "      <td>92.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>01</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>143.53</td>\n",
       "      <td>144.06</td>\n",
       "      <td>139.64</td>\n",
       "      <td>139.75</td>\n",
       "      <td>8089800</td>\n",
       "      <td>88.54</td>\n",
       "      <td>-0.039106</td>\n",
       "      <td>90.340000</td>\n",
       "      <td>90.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>01</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>139.94</td>\n",
       "      <td>141.53</td>\n",
       "      <td>137.25</td>\n",
       "      <td>140.00</td>\n",
       "      <td>12177900</td>\n",
       "      <td>88.70</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>89.793333</td>\n",
       "      <td>89.793333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>01</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>139.62</td>\n",
       "      <td>141.50</td>\n",
       "      <td>137.75</td>\n",
       "      <td>137.75</td>\n",
       "      <td>6227200</td>\n",
       "      <td>87.27</td>\n",
       "      <td>-0.016071</td>\n",
       "      <td>89.162500</td>\n",
       "      <td>89.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Friday</td>\n",
       "      <td>01</td>\n",
       "      <td>2000-01</td>\n",
       "      <td>140.31</td>\n",
       "      <td>145.75</td>\n",
       "      <td>140.06</td>\n",
       "      <td>145.75</td>\n",
       "      <td>8066500</td>\n",
       "      <td>92.34</td>\n",
       "      <td>0.058076</td>\n",
       "      <td>89.798000</td>\n",
       "      <td>89.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>2025</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>Monday</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-26</td>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>603.100714</td>\n",
       "      <td>579.810400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-01</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>2025</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-26</td>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>604.268571</td>\n",
       "      <td>581.666200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-02</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>2025</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-26</td>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>0.004533</td>\n",
       "      <td>605.758571</td>\n",
       "      <td>583.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-03</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>2025</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>26</td>\n",
       "      <td>2025-26</td>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>0.007881</td>\n",
       "      <td>607.427857</td>\n",
       "      <td>585.820600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-07</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>2025</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>Monday</td>\n",
       "      <td>27</td>\n",
       "      <td>2025-27</td>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>-0.007452</td>\n",
       "      <td>609.245000</td>\n",
       "      <td>587.557400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6415 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Date  Year Month Day    Weekday Week_Number Year_Week  \\\n",
       "Ticker                                                                   \n",
       "Date                                                                     \n",
       "2000-01-03 2000-01-03  2000     1   3     Monday          01   2000-01   \n",
       "2000-01-04 2000-01-04  2000     1   4    Tuesday          01   2000-01   \n",
       "2000-01-05 2000-01-05  2000     1   5  Wednesday          01   2000-01   \n",
       "2000-01-06 2000-01-06  2000     1   6   Thursday          01   2000-01   \n",
       "2000-01-07 2000-01-07  2000     1   7     Friday          01   2000-01   \n",
       "...               ...   ...   ...  ..        ...         ...       ...   \n",
       "2025-06-30 2025-06-30  2025     6  30     Monday          26   2025-26   \n",
       "2025-07-01 2025-07-01  2025     7   1    Tuesday          26   2025-26   \n",
       "2025-07-02 2025-07-02  2025     7   2  Wednesday          26   2025-26   \n",
       "2025-07-03 2025-07-03  2025     7   3   Thursday          26   2025-26   \n",
       "2025-07-07 2025-07-07  2025     7   7     Monday          27   2025-27   \n",
       "\n",
       "Price         Open    High     Low   Close    Volume Adj Close    Return  \\\n",
       "Ticker         SPY     SPY     SPY     SPY       SPY       SPY             \n",
       "Date                                                                       \n",
       "2000-01-03  148.25  148.25  143.88  145.44   8164300     92.14       NaN   \n",
       "2000-01-04  143.53  144.06  139.64  139.75   8089800     88.54 -0.039106   \n",
       "2000-01-05  139.94  141.53  137.25  140.00  12177900     88.70  0.001789   \n",
       "2000-01-06  139.62  141.50  137.75  137.75   6227200     87.27 -0.016071   \n",
       "2000-01-07  140.31  145.75  140.06  145.75   8066500     92.34  0.058076   \n",
       "...            ...     ...     ...     ...       ...       ...       ...   \n",
       "2025-06-30  617.38  619.22  615.04  617.85  92502500    617.85  0.004781   \n",
       "2025-07-01  616.36  618.83  615.52  617.65  70030100    617.65 -0.000324   \n",
       "2025-07-02  617.24  620.49  616.61  620.45  66510400    620.45  0.004533   \n",
       "2025-07-03  622.45  626.28  622.43  625.34  51065800    625.34  0.007881   \n",
       "2025-07-07  623.36  624.03  617.87  620.68  74814500    620.68 -0.007452   \n",
       "\n",
       "Price         Short_MA     Long_MA  \n",
       "Ticker                              \n",
       "Date                                \n",
       "2000-01-03   92.140000   92.140000  \n",
       "2000-01-04   90.340000   90.340000  \n",
       "2000-01-05   89.793333   89.793333  \n",
       "2000-01-06   89.162500   89.162500  \n",
       "2000-01-07   89.798000   89.798000  \n",
       "...                ...         ...  \n",
       "2025-06-30  603.100714  579.810400  \n",
       "2025-07-01  604.268571  581.666200  \n",
       "2025-07-02  605.758571  583.827800  \n",
       "2025-07-03  607.427857  585.820600  \n",
       "2025-07-07  609.245000  587.557400  \n",
       "\n",
       "[6415 rows x 16 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b11f608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ATR</th>\n",
       "      <th>SD_Log_Close</th>\n",
       "      <th>ATR_normalized</th>\n",
       "      <th>SD_normalized</th>\n",
       "      <th>atr_slope_7</th>\n",
       "      <th>stock_slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-20</td>\n",
       "      <td>146.97</td>\n",
       "      <td>146.97</td>\n",
       "      <td>143.81</td>\n",
       "      <td>144.75</td>\n",
       "      <td>5800100</td>\n",
       "      <td>91.71</td>\n",
       "      <td>2.370000</td>\n",
       "      <td>0.012651</td>\n",
       "      <td>-0.230495</td>\n",
       "      <td>0.347628</td>\n",
       "      <td>-0.368776</td>\n",
       "      <td>0.206786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-21</td>\n",
       "      <td>145.50</td>\n",
       "      <td>145.50</td>\n",
       "      <td>144.06</td>\n",
       "      <td>144.44</td>\n",
       "      <td>6244800</td>\n",
       "      <td>91.51</td>\n",
       "      <td>2.182857</td>\n",
       "      <td>0.011798</td>\n",
       "      <td>-0.304408</td>\n",
       "      <td>0.233226</td>\n",
       "      <td>-0.324388</td>\n",
       "      <td>0.232500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>145.66</td>\n",
       "      <td>145.84</td>\n",
       "      <td>139.41</td>\n",
       "      <td>140.34</td>\n",
       "      <td>7896900</td>\n",
       "      <td>88.92</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>-0.038097</td>\n",
       "      <td>0.779455</td>\n",
       "      <td>-0.182704</td>\n",
       "      <td>0.112143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>140.52</td>\n",
       "      <td>141.94</td>\n",
       "      <td>139.00</td>\n",
       "      <td>141.94</td>\n",
       "      <td>9942500</td>\n",
       "      <td>89.93</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>-0.023991</td>\n",
       "      <td>0.732997</td>\n",
       "      <td>-0.058980</td>\n",
       "      <td>-0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-26</td>\n",
       "      <td>141.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>140.09</td>\n",
       "      <td>140.81</td>\n",
       "      <td>5158100</td>\n",
       "      <td>89.21</td>\n",
       "      <td>2.804286</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>-0.058973</td>\n",
       "      <td>0.492267</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>-0.853929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>5.868571</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.151276</td>\n",
       "      <td>-0.589089</td>\n",
       "      <td>-0.111990</td>\n",
       "      <td>3.476429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>5.398571</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.965648</td>\n",
       "      <td>-0.766251</td>\n",
       "      <td>-0.221327</td>\n",
       "      <td>3.393929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>4.717143</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.696516</td>\n",
       "      <td>-0.825029</td>\n",
       "      <td>-0.318673</td>\n",
       "      <td>2.286429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.591007</td>\n",
       "      <td>-0.921698</td>\n",
       "      <td>-0.308265</td>\n",
       "      <td>2.271429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>5.078571</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.839263</td>\n",
       "      <td>-0.621569</td>\n",
       "      <td>-0.243827</td>\n",
       "      <td>2.218214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6403 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date    Open    High     Low   Close    Volume  Adj Close  \\\n",
       "0     2000-01-20  146.97  146.97  143.81  144.75   5800100      91.71   \n",
       "1     2000-01-21  145.50  145.50  144.06  144.44   6244800      91.51   \n",
       "2     2000-01-24  145.66  145.84  139.41  140.34   7896900      88.92   \n",
       "3     2000-01-25  140.52  141.94  139.00  141.94   9942500      89.93   \n",
       "4     2000-01-26  141.00  141.55  140.09  140.81   5158100      89.21   \n",
       "...          ...     ...     ...     ...     ...       ...        ...   \n",
       "6398  2025-06-30  617.38  619.22  615.04  617.85  92502500     617.85   \n",
       "6399  2025-07-01  616.36  618.83  615.52  617.65  70030100     617.65   \n",
       "6400  2025-07-02  617.24  620.49  616.61  620.45  66510400     620.45   \n",
       "6401  2025-07-03  622.45  626.28  622.43  625.34  51065800     625.34   \n",
       "6402  2025-07-07  623.36  624.03  617.87  620.68  74814500     620.68   \n",
       "\n",
       "Price       ATR  SD_Log_Close  ATR_normalized  SD_normalized  atr_slope_7  \\\n",
       "0      2.370000      0.012651       -0.230495       0.347628    -0.368776   \n",
       "1      2.182857      0.011798       -0.304408       0.233226    -0.324388   \n",
       "2      2.857143      0.015872       -0.038097       0.779455    -0.182704   \n",
       "3      2.892857      0.015525       -0.023991       0.732997    -0.058980   \n",
       "4      2.804286      0.013730       -0.058973       0.492267     0.042857   \n",
       "...         ...           ...             ...            ...          ...   \n",
       "6398   5.868571      0.005666        1.151276      -0.589089    -0.111990   \n",
       "6399   5.398571      0.004345        0.965648      -0.766251    -0.221327   \n",
       "6400   4.717143      0.003906        0.696516      -0.825029    -0.318673   \n",
       "6401   4.450000      0.003185        0.591007      -0.921698    -0.308265   \n",
       "6402   5.078571      0.005424        0.839263      -0.621569    -0.243827   \n",
       "\n",
       "Price  stock_slope  \n",
       "0         0.206786  \n",
       "1         0.232500  \n",
       "2         0.112143  \n",
       "3        -0.614286  \n",
       "4        -0.853929  \n",
       "...            ...  \n",
       "6398      3.476429  \n",
       "6399      3.393929  \n",
       "6400      2.286429  \n",
       "6401      2.271429  \n",
       "6402      2.218214  \n",
       "\n",
       "[6403 rows x 13 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55e954c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4b1c21b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(133.23982522451678)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def run_sim(df_n):\n",
    "    money = 200\n",
    "    shares = 0\n",
    "    for i in range(len(df_n['Open'])):\n",
    "        price = money/df_n['Open'].loc[i]\n",
    "        if (df_n['atr_slope_7'].loc[i] < 0) & (df_n['stock_slope'].loc[i] > 0):\n",
    "            max_shares = math.floor(price)\n",
    "            shares += max_shares\n",
    "            money -= (max_shares * price)\n",
    "        elif (df_n['atr_slope_7'].loc[i] > 0) & (df_n['stock_slope'].loc[i] < 0):\n",
    "            money+= (shares*price)\n",
    "            shares = 0\n",
    "    money+= (shares*price)\n",
    "    shares = 0\n",
    "\n",
    "    return money\n",
    "\n",
    "run_sim(df_n)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
