{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "775d4daa",
   "metadata": {},
   "source": [
    "# Retrieve Stock Data and Save to DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033fed49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05151c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def get_stock(ticker, start_date, end_date, s_window, l_window):\n",
    "    try:\n",
    "        #yf.pdr_override()\n",
    "        df = yf.download(ticker, start=start_date, end=end_date,auto_adjust=False)\n",
    "        #print(\"DF: \",df)\n",
    "# can use this as well        df = web.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "        df['Return'] = df['Adj Close'].pct_change()\n",
    "        df['Return'].fillna(0, inplace = True)\n",
    "        df['Date'] = df.index\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['Year'] = df['Date'].dt.year \n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Adj Close']:\n",
    "            df[col] = df[col].round(2)\n",
    "        df['Weekday'] = df['Date'].dt.day_name()\n",
    "        df['Week_Number'] = df['Date'].dt.strftime('%U')\n",
    "        df['Year_Week'] = df['Date'].dt.strftime('%Y-%U')\n",
    "        df['Short_MA'] = df['Adj Close'].rolling(window=s_window, min_periods=1).mean()\n",
    "        df['Long_MA'] = df['Adj Close'].rolling(window=l_window, min_periods=1).mean()        \n",
    "        col_list = ['Date', 'Year', 'Month', 'Day', 'Weekday', \n",
    "                    'Week_Number', 'Year_Week', 'Open', \n",
    "                    'High', 'Low', 'Close', 'Volume', 'Adj Close',\n",
    "                    'Return', 'Short_MA', 'Long_MA']\n",
    "        num_lines = len(df)\n",
    "        df = df[col_list]\n",
    "        print('read ', num_lines, ' lines of data for ticker: ' , ticker)\n",
    "        return df\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ticker='SPY'\n",
    "    input_dir = os.getcwd()\n",
    "    output_file = os.path.join(input_dir, ticker + '.csv')\n",
    "    df = get_stock(ticker, start_date='2000-01-01', end_date='2025-07-08', \n",
    "               s_window=14, l_window=50)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print('wrote ' + str(len(df)) + ' lines to file: ' + output_file)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('failed to get Yahoo stock data for ticker: ', ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79956dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#psuedocode\n",
    "'''\n",
    "1. create ATR column\n",
    "2. create SD column\n",
    "3. build LSTM columnn\n",
    "4. split into train and test\n",
    "5. train lstm on training data for ATR and test\n",
    "6. train lstm on training data for SD and test\n",
    "7. plot results and avg. returns based on decisions (buy if delta_volatility<-alpha, sell if delta_volatility>alpha)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91feef9",
   "metadata": {},
   "outputs": [],
   "source": [
    " #.xs returns a cross section; selects only values within the SPY indexes at level=1\n",
    "df_n= df.xs('SPY',axis=1,level=1)\n",
    "#cleaned up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# #challenge of how to deal with missing values in time series data\n",
    "# #choose sliding window of length=N (could be 20?) N_lstmtraining>N_atrslidingwindow\n",
    "# def atr_func(d):\n",
    "#     running = 0\n",
    "#     for i in range(len(d)):\n",
    "#         high = d.loc[i,\"High\"]\n",
    "#         low = d.loc[i,\"Low\"]\n",
    "#         if i==0:\n",
    "#             running += high-low\n",
    "#             continue\n",
    "#         if i>0:\n",
    "#             y_close = d.loc[i,\"Close\"]\n",
    "        \n",
    "#         TR = max(high-low,max(math.abs(high-y_close),math.abs(low-y_close)))\n",
    "#         running+=TR\n",
    "#     return running/len(d)\n",
    "\n",
    "# df_n['ATR'] = df_n.rolling(window=14).apply(atr_func)\n",
    "# df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c5bb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define ATR columns\n",
    "high = df_n[\"High\"]\n",
    "low = df_n[\"Low\"]\n",
    "close = df_n[\"Close\"]\n",
    "\n",
    "prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "tr = pd.concat([\n",
    "    high - low,\n",
    "    (high - prev_close).abs(),\n",
    "    (low - prev_close).abs()\n",
    "], axis=1).max(axis=1)\n",
    "\n",
    "df_n[\"ATR\"] = tr.rolling(7).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aca5313f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ATR</th>\n",
       "      <th>SD_Log_Close</th>\n",
       "      <th>ATR_normalized</th>\n",
       "      <th>SD_normalized</th>\n",
       "      <th>Delta_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-12</td>\n",
       "      <td>144.59</td>\n",
       "      <td>144.59</td>\n",
       "      <td>142.88</td>\n",
       "      <td>143.06</td>\n",
       "      <td>6907700</td>\n",
       "      <td>90.64</td>\n",
       "      <td>4.024286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.422937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-13</td>\n",
       "      <td>144.47</td>\n",
       "      <td>145.75</td>\n",
       "      <td>143.28</td>\n",
       "      <td>145.00</td>\n",
       "      <td>5158300</td>\n",
       "      <td>91.87</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-14</td>\n",
       "      <td>146.53</td>\n",
       "      <td>147.47</td>\n",
       "      <td>145.97</td>\n",
       "      <td>146.97</td>\n",
       "      <td>7437300</td>\n",
       "      <td>93.11</td>\n",
       "      <td>3.321429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-18</td>\n",
       "      <td>145.34</td>\n",
       "      <td>146.62</td>\n",
       "      <td>145.19</td>\n",
       "      <td>145.81</td>\n",
       "      <td>6488500</td>\n",
       "      <td>92.38</td>\n",
       "      <td>3.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>145.31</td>\n",
       "      <td>147.00</td>\n",
       "      <td>145.00</td>\n",
       "      <td>147.00</td>\n",
       "      <td>6157900</td>\n",
       "      <td>93.13</td>\n",
       "      <td>2.182857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.304303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>5.868571</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.151305</td>\n",
       "      <td>-0.588181</td>\n",
       "      <td>9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>5.398571</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.965687</td>\n",
       "      <td>-0.765501</td>\n",
       "      <td>9302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>4.717143</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.696569</td>\n",
       "      <td>-0.824331</td>\n",
       "      <td>9303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>-0.921087</td>\n",
       "      <td>9304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>5.078571</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.839308</td>\n",
       "      <td>-0.620691</td>\n",
       "      <td>9308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6408 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price       Date    Open    High     Low   Close    Volume  Adj Close  \\\n",
       "0     2000-01-12  144.59  144.59  142.88  143.06   6907700      90.64   \n",
       "1     2000-01-13  144.47  145.75  143.28  145.00   5158300      91.87   \n",
       "2     2000-01-14  146.53  147.47  145.97  146.97   7437300      93.11   \n",
       "3     2000-01-18  145.34  146.62  145.19  145.81   6488500      92.38   \n",
       "4     2000-01-19  145.31  147.00  145.00  147.00   6157900      93.13   \n",
       "...          ...     ...     ...     ...     ...       ...        ...   \n",
       "6403  2025-06-30  617.38  619.22  615.04  617.85  92502500     617.85   \n",
       "6404  2025-07-01  616.36  618.83  615.52  617.65  70030100     617.65   \n",
       "6405  2025-07-02  617.24  620.49  616.61  620.45  66510400     620.45   \n",
       "6406  2025-07-03  622.45  626.28  622.43  625.34  51065800     625.34   \n",
       "6407  2025-07-07  623.36  624.03  617.87  620.68  74814500     620.68   \n",
       "\n",
       "Price       ATR  SD_Log_Close  ATR_normalized  SD_normalized  Delta_Days  \n",
       "0      4.024286           NaN        0.422937            NaN           0  \n",
       "1      3.580000           NaN        0.247474            NaN           1  \n",
       "2      3.321429           NaN        0.145356            NaN           2  \n",
       "3      3.040000           NaN        0.034211            NaN           6  \n",
       "4      2.182857           NaN       -0.304303            NaN           7  \n",
       "...         ...           ...             ...            ...         ...  \n",
       "6403   5.868571      0.005666        1.151305      -0.588181        9301  \n",
       "6404   5.398571      0.004345        0.965687      -0.765501        9302  \n",
       "6405   4.717143      0.003906        0.696569      -0.824331        9303  \n",
       "6406   4.450000      0.003185        0.591065      -0.921087        9304  \n",
       "6407   5.078571      0.005424        0.839308      -0.620691        9308  \n",
       "\n",
       "[6408 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "#xlb, xle, \n",
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6eb499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_9888\\2293412753.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#drop na values (first 6 rows)\u001b[39;00m\n\u001b[32m      2\u001b[39m df_n = df_n.dropna()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_n = df_n.reset_index()\n\u001b[32m      4\u001b[39m df_n[\u001b[33m\"index\"\u001b[39m] = df_n[\u001b[33m\"index\"\u001b[39m]%\u001b[32m7\u001b[39m\n",
      "\u001b[32mc:\\Users\\aksha\\anaconda3\\envs\\lab_5\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[39m\n\u001b[32m   6468\u001b[39m                     level_values = algorithms.take(\n\u001b[32m   6469\u001b[39m                         level_values, lab, allow_fill=\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value=lev._na_value\n\u001b[32m   6470\u001b[39m                     )\n\u001b[32m   6471\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m6472\u001b[39m                 new_obj.insert(\n\u001b[32m   6473\u001b[39m                     \u001b[32m0\u001b[39m,\n\u001b[32m   6474\u001b[39m                     name,\n\u001b[32m   6475\u001b[39m                     level_values,\n",
      "\u001b[32mc:\\Users\\aksha\\anaconda3\\envs\\lab_5\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, loc, column, value, allow_duplicates)\u001b[39m\n\u001b[32m   5154\u001b[39m                 \u001b[33m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[39m\n\u001b[32m   5155\u001b[39m             )\n\u001b[32m   5156\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;28;01mand\u001b[39;00m column \u001b[38;5;28;01min\u001b[39;00m self.columns:\n\u001b[32m   5157\u001b[39m             \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5158\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(f\"cannot insert {column}, already exists\")\n\u001b[32m   5159\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_integer(loc):\n\u001b[32m   5160\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"loc must be int\"\u001b[39m)\n\u001b[32m   5161\u001b[39m         \u001b[38;5;66;03m# convert non stdlib ints to satisfy typing checks\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "#drop na values (first 6 rows)\n",
    "df_n = df_n.dropna()\n",
    "df_n = df_n.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dbb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n[\"index\"] = df_n[\"index\"]%7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3993a7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>ATR</th>\n",
       "      <th>SD_Log_Close</th>\n",
       "      <th>ATR_normalized</th>\n",
       "      <th>SD_normalized</th>\n",
       "      <th>Delta_Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000-01-24</td>\n",
       "      <td>145.66</td>\n",
       "      <td>145.84</td>\n",
       "      <td>139.41</td>\n",
       "      <td>140.34</td>\n",
       "      <td>7896900</td>\n",
       "      <td>88.92</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>0.015872</td>\n",
       "      <td>-0.038005</td>\n",
       "      <td>0.781583</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-25</td>\n",
       "      <td>140.52</td>\n",
       "      <td>141.94</td>\n",
       "      <td>139.00</td>\n",
       "      <td>141.94</td>\n",
       "      <td>9942500</td>\n",
       "      <td>89.93</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>-0.023901</td>\n",
       "      <td>0.735084</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2000-01-26</td>\n",
       "      <td>141.00</td>\n",
       "      <td>141.55</td>\n",
       "      <td>140.09</td>\n",
       "      <td>140.81</td>\n",
       "      <td>5158100</td>\n",
       "      <td>89.21</td>\n",
       "      <td>2.804286</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>-0.058880</td>\n",
       "      <td>0.494139</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-27</td>\n",
       "      <td>141.84</td>\n",
       "      <td>142.22</td>\n",
       "      <td>138.12</td>\n",
       "      <td>140.25</td>\n",
       "      <td>10922700</td>\n",
       "      <td>88.86</td>\n",
       "      <td>3.135714</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.493374</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-01-28</td>\n",
       "      <td>139.44</td>\n",
       "      <td>140.06</td>\n",
       "      <td>135.53</td>\n",
       "      <td>135.88</td>\n",
       "      <td>11916200</td>\n",
       "      <td>86.08</td>\n",
       "      <td>3.524286</td>\n",
       "      <td>0.015265</td>\n",
       "      <td>0.225471</td>\n",
       "      <td>0.700118</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>6396</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-06-30</td>\n",
       "      <td>617.38</td>\n",
       "      <td>619.22</td>\n",
       "      <td>615.04</td>\n",
       "      <td>617.85</td>\n",
       "      <td>92502500</td>\n",
       "      <td>617.85</td>\n",
       "      <td>5.868571</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>1.151305</td>\n",
       "      <td>-0.588181</td>\n",
       "      <td>9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>6397</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>616.36</td>\n",
       "      <td>618.83</td>\n",
       "      <td>615.52</td>\n",
       "      <td>617.65</td>\n",
       "      <td>70030100</td>\n",
       "      <td>617.65</td>\n",
       "      <td>5.398571</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.965687</td>\n",
       "      <td>-0.765501</td>\n",
       "      <td>9302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>6398</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-07-02</td>\n",
       "      <td>617.24</td>\n",
       "      <td>620.49</td>\n",
       "      <td>616.61</td>\n",
       "      <td>620.45</td>\n",
       "      <td>66510400</td>\n",
       "      <td>620.45</td>\n",
       "      <td>4.717143</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.696569</td>\n",
       "      <td>-0.824331</td>\n",
       "      <td>9303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>6399</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-07-03</td>\n",
       "      <td>622.45</td>\n",
       "      <td>626.28</td>\n",
       "      <td>622.43</td>\n",
       "      <td>625.34</td>\n",
       "      <td>51065800</td>\n",
       "      <td>625.34</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>-0.921087</td>\n",
       "      <td>9304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>6400</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-07-07</td>\n",
       "      <td>623.36</td>\n",
       "      <td>624.03</td>\n",
       "      <td>617.87</td>\n",
       "      <td>620.68</td>\n",
       "      <td>74814500</td>\n",
       "      <td>620.68</td>\n",
       "      <td>5.078571</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.839308</td>\n",
       "      <td>-0.620691</td>\n",
       "      <td>9308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6401 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price  level_0  index       Date    Open    High     Low   Close    Volume  \\\n",
       "0            0      0 2000-01-24  145.66  145.84  139.41  140.34   7896900   \n",
       "1            1      1 2000-01-25  140.52  141.94  139.00  141.94   9942500   \n",
       "2            2      2 2000-01-26  141.00  141.55  140.09  140.81   5158100   \n",
       "3            3      3 2000-01-27  141.84  142.22  138.12  140.25  10922700   \n",
       "4            4      4 2000-01-28  139.44  140.06  135.53  135.88  11916200   \n",
       "...        ...    ...        ...     ...     ...     ...     ...       ...   \n",
       "6396      6396      5 2025-06-30  617.38  619.22  615.04  617.85  92502500   \n",
       "6397      6397      6 2025-07-01  616.36  618.83  615.52  617.65  70030100   \n",
       "6398      6398      0 2025-07-02  617.24  620.49  616.61  620.45  66510400   \n",
       "6399      6399      1 2025-07-03  622.45  626.28  622.43  625.34  51065800   \n",
       "6400      6400      2 2025-07-07  623.36  624.03  617.87  620.68  74814500   \n",
       "\n",
       "Price  Adj Close       ATR  SD_Log_Close  ATR_normalized  SD_normalized  \\\n",
       "0          88.92  2.857143      0.015872       -0.038005       0.781583   \n",
       "1          89.93  2.892857      0.015525       -0.023901       0.735084   \n",
       "2          89.21  2.804286      0.013730       -0.058880       0.494139   \n",
       "3          88.86  3.135714      0.013724        0.072011       0.493374   \n",
       "4          86.08  3.524286      0.015265        0.225471       0.700118   \n",
       "...          ...       ...           ...             ...            ...   \n",
       "6396      617.85  5.868571      0.005666        1.151305      -0.588181   \n",
       "6397      617.65  5.398571      0.004345        0.965687      -0.765501   \n",
       "6398      620.45  4.717143      0.003906        0.696569      -0.824331   \n",
       "6399      625.34  4.450000      0.003185        0.591065      -0.921087   \n",
       "6400      620.68  5.078571      0.005424        0.839308      -0.620691   \n",
       "\n",
       "Price  Delta_Days  \n",
       "0              12  \n",
       "1              13  \n",
       "2              14  \n",
       "3              15  \n",
       "4              16  \n",
       "...           ...  \n",
       "6396         9301  \n",
       "6397         9302  \n",
       "6398         9303  \n",
       "6399         9304  \n",
       "6400         9308  \n",
       "\n",
       "[6401 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d95f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_n[\"Delta_Days\"] = [(df_n.loc[i,\"Date\"] - df_n.loc[0,\"Date\"]).days for i in range(len(df_n))]\n",
    "# #save clean data\n",
    "# df_n.to_csv(\"Clean_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ccea72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lstm model\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NN_LSTM(Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size,hidden_size=30)\n",
    "        self.fc = Linear(30,output_size)\n",
    "    def activation(self,X):\n",
    "        return F.relu(X)\n",
    "    def forward(self,input):\n",
    "        input,_ = self.lstm(input)\n",
    "        input = self.fc(input[-1,:,:])\n",
    "        return input #return the last prediction\n",
    "#lstm_layer = LSTM(input_size=4,hidden_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a557c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define PDE loss\n",
    "def PDE_loss(v_hat,):\n",
    "    return 0\n",
    "    #use torch.autograd to get PDE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9134de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0bbb3ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(df_n,vol_metric):\n",
    "    train = df_n.loc[[i<=len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_train = train[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_train = train[vol_metric].to_numpy()\n",
    "\n",
    "    test = df_n.loc[[i>len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_test = test[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_test = test[vol_metric].to_numpy()\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "X_train,y_train,X_test,y_test = tt_split(df_n,\"ATR_normalized\")\n",
    "\n",
    "#bollinger bands\n",
    "#try moving median instead of moving average\n",
    "#try moving quartiles instead of std; q3-q2  *1/2\n",
    "#take longer time period - five years\n",
    "\n",
    "#lstm,cnn,and rnn cant either predict directional volatiliy for xl stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76390f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(X_train,y_train,X_test,y_test):\n",
    "    T = 30  # sequence length (window size)\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    X_seq_test = []\n",
    "    y_seq_test = []\n",
    "\n",
    "    for i in range(len(X_train) - T):\n",
    "        X_seq.append(X_train[i:i+T])  # shape: [T, 6] <- what is wanted in lstm\n",
    "        y_seq.append(y_train[i+T])    # predict next ATR value\n",
    "    for i in range(len(X_test)-T):    \n",
    "        X_seq_test.append(X_test[i:i+T])\n",
    "        y_seq_test.append(y_test[i+T])\n",
    "\n",
    "\n",
    "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "    y_seq = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
    "    X_seq_test = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "    y_seq_test = torch.tensor(y_seq_test, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return X_seq,y_seq,X_seq_test,y_seq_test\n",
    "X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1bd9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_loaders(X_seq,y_seq,X_seq_test,y_seq_test,batch_size=64):\n",
    "    dataset = TensorDataset(X_seq, y_seq)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(X_seq_test,y_seq_test)\n",
    "    loader_test = DataLoader(dataset_test,batch_size=batch_size,shuffle=True)\n",
    "    return loader,loader_test\n",
    "loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training loop\n",
    "# model = NN_LSTM(input_size=5,output_size=1)\n",
    "# epochs = 100\n",
    "# optim = torch.optim.Adam(params = model.parameters())\n",
    "# crit = MSELoss()\n",
    "# losses = []\n",
    "# losses_test = []\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for x_window,y_atr in loader:\n",
    "#         #print(\"Running\")\n",
    "#         input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "#         out = model(input)\n",
    "#         #print(y_atr.shape)\n",
    "#         #print(out,y_atr)\n",
    "#         #break\n",
    "#         loss = crit(out,y_atr)\n",
    "#         running_loss+=loss.item()\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#             # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "#     #break\n",
    "#     running_loss/=(len(loader))\n",
    "#     #print(f\"Training Loss: {running_loss}\")\n",
    "#     losses.append(running_loss)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         testing_loss = 0\n",
    "#         for x_window_test,y_atr_test in loader_test:\n",
    "#             out_test = model(x_window_test.permute(1,0,2))\n",
    "#             #print(y_atr_test.shape)\n",
    "#             loss = crit(out_test,y_atr_test)\n",
    "#             testing_loss+=loss.item()\n",
    "#         losses_test.append(testing_loss/(len(loader_test)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "# plt.title(\"Training Loss of LSTM (ATR_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6278da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses_test)\n",
    "# plt.title(\"Testing Loss of LSTM (ATR_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21004adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sd,y_train_sd,X_test_sd,y_test_sd = tt_split(df_n,vol_metric=\"SD_normalized\")\n",
    "# X_seq_sd,y_seq_sd,X_seq_test_sd,y_seq_test_sd = make_seq(X_train_sd,y_train_sd,X_test_sd,y_test_sd)\n",
    "# loader_sd,loader_test_sd = create_loaders(X_seq_sd,y_seq_sd,X_seq_test_sd,y_seq_test_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7127c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training loop\n",
    "# model_sd = NN_LSTM(input_size=5,output_size=1)\n",
    "# epochs = 100\n",
    "# optim = torch.optim.Adam(params = model_sd.parameters())\n",
    "# crit = MSELoss()\n",
    "# losses = []\n",
    "# losses_test = []\n",
    "\n",
    "# for i in range(epochs):\n",
    "#     running_loss = 0\n",
    "#     for x_window,y_sd in loader_sd:\n",
    "#         #print(\"Running\")\n",
    "#         input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "#         out = model_sd(input)\n",
    "#         #print(y_sd.shape)\n",
    "#         loss = crit(out,y_sd)\n",
    "#         running_loss+=loss.item()\n",
    "#         optim.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optim.step()\n",
    "#             # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "#     running_loss/=(len(loader_sd))\n",
    "#     #print(f\"Training Loss: {running_loss}\")\n",
    "#     losses.append(running_loss)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         testing_loss = 0\n",
    "#         for x_window_test,y_sd_test in loader_test_sd:\n",
    "#             out_test = model_sd(x_window_test.permute(1,0,2))\n",
    "#             #print(y_sd_test.shape)\n",
    "#             loss = crit(out_test,y_sd_test)\n",
    "#             testing_loss+=loss.item()\n",
    "#         losses_test.append(testing_loss/(len(loader_test_sd)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f08d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses)\n",
    "# plt.title(\"Training Loss of LSTM (SD__normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181f8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.lineplot(losses_test)\n",
    "# plt.title(\"Testing Loss of LSTM (SD_normalized) across 60 epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd62e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use past atrs\n",
    "#try transformations of atr log(atr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f219ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(ticker,start,end,metric):\n",
    "    df = get_stock(ticker,start_date=start,end_date=end,s_window=14,l_window=50)\n",
    "    df_n= df.xs(ticker,axis=1,level=1)\n",
    "    \n",
    "        #define ATR columns\n",
    "    high = df_n[\"High\"]\n",
    "    low = df_n[\"Low\"]\n",
    "    close = df_n[\"Close\"]\n",
    "\n",
    "    prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - prev_close).abs(),\n",
    "        (low - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    df_n[\"ATR\"] = tr.rolling(7).mean()\n",
    "    \n",
    "    log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "    df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "    df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "    df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "\n",
    "    df_n = df_n.dropna()\n",
    "    df_n = df_n.reset_index()\n",
    "    df_n[\"index\"] = df_n.index%7 \n",
    "    print(df_n)\n",
    "\n",
    "    X_train,y_train,X_test,y_test = tt_split(df_n, metric)\n",
    "\n",
    "    X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)\n",
    "\n",
    "    loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)\n",
    "\n",
    "    #training loop\n",
    "    \n",
    "    model = NN_LSTM(input_size=6,output_size=1)\n",
    "    epochs = 100\n",
    "    optim = torch.optim.Adam(params = model.parameters())\n",
    "    crit = MSELoss()\n",
    "    losses = []\n",
    "    losses_test = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for x_window,y_atr in loader:\n",
    "            #print(\"Running\")\n",
    "            input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "            out = model(input)\n",
    "            #print(y_atr.shape)\n",
    "            #print(out,y_atr)\n",
    "            #break\n",
    "            loss = crit(out,y_atr)\n",
    "            running_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "                # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "        #break\n",
    "        running_loss/=(len(loader))\n",
    "        #print(f\"Training Loss: {running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            testing_loss = 0\n",
    "            for x_window_test,y_atr_test in loader_test:\n",
    "                out_test = model(x_window_test.permute(1,0,2))\n",
    "                #print(y_atr_test.shape)\n",
    "                loss = crit(out_test,y_atr_test)\n",
    "                testing_loss+=loss.item()\n",
    "            losses_test.append(testing_loss/(len(loader_test)))\n",
    "\n",
    "    sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "    plt.title(f\"Training Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.lineplot(losses_test)\n",
    "    plt.title(f\"Testing Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    return min(losses),min(losses_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa8faf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = \"2000-01-01\"\n",
    "end = \"2025-07-14\"\n",
    "#pipeline(\"SPY\",start,end,metric=\"ATR_normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b6c59dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline(\"XLP\",start,end,metric=\"SD_normalized\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6154311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "33fc6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read  6419  lines of data for ticker:  XLB\n",
      "Price       Date   Open   High    Low  Close   Volume  Adj Close       ATR  \\\n",
      "0     2000-01-12  26.61  27.03  26.61  26.64   135300      15.04  0.640000   \n",
      "1     2000-01-13  26.89  26.97  26.62  26.75    45900      15.11  0.627143   \n",
      "2     2000-01-14  26.52  26.72  26.44  26.56    76000      15.00  0.515714   \n",
      "3     2000-01-18  26.22  26.31  25.69  25.92    34400      14.64  0.504286   \n",
      "4     2000-01-19  25.78  25.95  25.42  25.42   125700      14.36  0.510000   \n",
      "...          ...    ...    ...    ...    ...      ...        ...       ...   \n",
      "6407  2025-07-07  90.90  91.22  90.01  90.49  5880800      90.49  1.254286   \n",
      "6408  2025-07-08  90.68  91.52  90.57  91.23  8173800      91.23  1.224286   \n",
      "6409  2025-07-09  91.47  91.88  90.92  91.78  6717800      91.78  1.235714   \n",
      "6410  2025-07-10  92.00  92.86  91.81  92.27  6432800      92.27  1.297143   \n",
      "6411  2025-07-11  91.28  91.68  90.81  91.52  5781600      91.52  1.108571   \n",
      "\n",
      "Price  SD_Log_Close  ATR_normalized  SD_normalized  index  \n",
      "0          0.021011       -0.337562       1.019430      0  \n",
      "1          0.020186       -0.364605       0.916591      1  \n",
      "2          0.013385       -0.598982       0.069896      2  \n",
      "3          0.009580       -0.623021      -0.403946      3  \n",
      "4          0.009731       -0.611001      -0.385123      4  \n",
      "...             ...             ...            ...    ...  \n",
      "6407       0.011869        0.954516      -0.118919      2  \n",
      "6408       0.011713        0.891415      -0.138294      3  \n",
      "6409       0.011562        0.915453      -0.157092      4  \n",
      "6410       0.011158        1.044661      -0.207498      5  \n",
      "6411       0.008915        0.648023      -0.486718      6  \n",
      "\n",
      "[6412 rows x 12 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "etfs = ['XLB','XLE','XLF','XLI','XLP','XLV','XLY','XLU']\n",
    "metrics = [\"ATR_normalized\",\"SD_normalized\"]\n",
    "df = pd.DataFrame({\"etf\":[],\"metric\":[],\"train_loss\":[],\"test_loss\":[]})\n",
    "for etf in etfs[:2]:\n",
    "    for metric in metrics:\n",
    "        train_loss_atr, test_loss_atr = pipeline(etf,start,end,metric=metric)\n",
    "        df.loc[len(df)] = [etf,metric,train_loss_atr,test_loss_atr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44015da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c21b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
