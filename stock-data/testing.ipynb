{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6ae6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f2e6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stock(ticker, start_date, end_date, s_window, l_window):\n",
    "    try:\n",
    "        #yf.pdr_override()\n",
    "        df = yf.download(ticker, start=start_date, end=end_date,auto_adjust=False)\n",
    "        #print(\"DF: \",df)\n",
    "# can use this as well        df = web.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "        df['Return'] = df['Adj Close'].pct_change()\n",
    "        df['Return'].fillna(0, inplace = True)\n",
    "        df['Date'] = df.index\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['Year'] = df['Date'].dt.year \n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Adj Close']:\n",
    "            df[col] = df[col].round(2)\n",
    "        df['Weekday'] = df['Date'].dt.day_name()\n",
    "        df['Week_Number'] = df['Date'].dt.strftime('%U')\n",
    "        df['Year_Week'] = df['Date'].dt.strftime('%Y-%U')\n",
    "        df['Short_MA'] = df['Adj Close'].rolling(window=s_window, min_periods=1).mean()\n",
    "        df['Long_MA'] = df['Adj Close'].rolling(window=l_window, min_periods=1).mean()        \n",
    "        col_list = ['Date', 'Year', 'Month', 'Day', 'Weekday', \n",
    "                    'Week_Number', 'Year_Week', 'Open', \n",
    "                    'High', 'Low', 'Close', 'Volume', 'Adj Close',\n",
    "                    'Return', 'Short_MA', 'Long_MA']\n",
    "        num_lines = len(df)\n",
    "        df = df[col_list]\n",
    "        print('read ', num_lines, ' lines of data for ticker: ' , ticker)\n",
    "        return df\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47c7b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_LSTM(Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size,hidden_size=30)\n",
    "        self.fc = Linear(30,output_size)\n",
    "    def activation(self,X):\n",
    "        return F.relu(X)\n",
    "    def forward(self,input):\n",
    "        input,_ = self.lstm(input)\n",
    "        input = self.fc(input[-1,:,:])\n",
    "        return input #return the last prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5357aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(df_n,vol_metric):\n",
    "    train = df_n.loc[[i<=len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_train = train[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_train = train[vol_metric].to_numpy()\n",
    "\n",
    "    test = df_n.loc[[i>len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_test = test[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_test = test[vol_metric].to_numpy()\n",
    "    return X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7812d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(X_train,y_train,X_test,y_test):\n",
    "    T = 30  # sequence length (window size)\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    X_seq_test = []\n",
    "    y_seq_test = []\n",
    "\n",
    "    for i in range(len(X_train) - T):\n",
    "        X_seq.append(X_train[i:i+T])  # shape: [T, 6] <- what is wanted in lstm\n",
    "        y_seq.append(y_train[i+T])    # predict next ATR value\n",
    "    for i in range(len(X_test)-T):    \n",
    "        X_seq_test.append(X_test[i:i+T])\n",
    "        y_seq_test.append(y_test[i+T])\n",
    "\n",
    "\n",
    "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "    y_seq = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
    "    X_seq_test = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "    y_seq_test = torch.tensor(y_seq_test, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return X_seq,y_seq,X_seq_test,y_seq_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3fd2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def create_loaders(X_seq,y_seq,X_seq_test,y_seq_test,batch_size=64):\n",
    "    dataset = TensorDataset(X_seq, y_seq)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(X_seq_test,y_seq_test)\n",
    "    loader_test = DataLoader(dataset_test,batch_size=batch_size,shuffle=True)\n",
    "    return loader,loader_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1888351d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(ticker,start,end,metric):\n",
    "    df = get_stock(ticker,start_date=start,end_date=end,s_window=14,l_window=50)\n",
    "    df_n= df.xs(ticker,axis=1,level=1)\n",
    "    \n",
    "        #define ATR columns\n",
    "    high = df_n[\"High\"]\n",
    "    low = df_n[\"Low\"]\n",
    "    close = df_n[\"Close\"]\n",
    "\n",
    "    prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - prev_close).abs(),\n",
    "        (low - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    df_n[\"ATR\"] = tr.rolling(7).mean()\n",
    "    \n",
    "    log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "    df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "    df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "    df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "\n",
    "    df_n = df_n.dropna()\n",
    "    df_n = df_n.reset_index()\n",
    "    df_n[\"index\"] = df_n.index%7 \n",
    "    #print(df_n)\n",
    "\n",
    "    X_train,y_train,X_test,y_test = tt_split(df_n, metric)\n",
    "\n",
    "    X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)\n",
    "\n",
    "    loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)\n",
    "\n",
    "    #training loop\n",
    "    \n",
    "    model = NN_LSTM(input_size=6,output_size=1)\n",
    "    epochs = 100\n",
    "    optim = torch.optim.Adam(params = model.parameters())\n",
    "    crit = MSELoss()\n",
    "    losses = []\n",
    "    losses_test = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for x_window,y_atr in loader:\n",
    "            #print(\"Running\")\n",
    "            input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "            out = model(input)\n",
    "            #print(y_atr.shape)\n",
    "            #print(out,y_atr)\n",
    "            #break\n",
    "            loss = crit(out,y_atr)\n",
    "            running_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "                # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "        #break\n",
    "        running_loss/=(len(loader))\n",
    "        #print(f\"Training Loss: {running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            testing_loss = 0\n",
    "            for x_window_test,y_atr_test in loader_test:\n",
    "                out_test = model(x_window_test.permute(1,0,2))\n",
    "                #print(y_atr_test.shape)\n",
    "                loss = crit(out_test,y_atr_test)\n",
    "                testing_loss+=loss.item()\n",
    "            losses_test.append(testing_loss/(len(loader_test)))\n",
    "\n",
    "    sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "    plt.title(f\"Training Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    sns.lineplot(losses_test)\n",
    "    plt.title(f\"Testing Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "\n",
    "    return min(losses),min(losses_test)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99cf5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "start = \"2000-01-01\"\n",
    "end = \"2025-07-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30330149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read  6419  lines of data for ticker:  XLB\n"
     ]
    }
   ],
   "source": [
    "etfs = ['XLB','XLE','XLF','XLI','XLP','XLV','XLY','XLU']\n",
    "metrics = [\"ATR_normalized\",\"SD_normalized\"]\n",
    "df = pd.DataFrame({\"etf\":[],\"metric\":[],\"train_loss\":[],\"test_loss\":[]})\n",
    "for etf in etfs[:2]:\n",
    "    for metric in metrics:\n",
    "        train_loss_atr, test_loss_atr = pipeline(etf,start,end,metric=metric)\n",
    "        df.loc[len(df)] = [etf,metric,train_loss_atr,test_loss_atr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5e72b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
