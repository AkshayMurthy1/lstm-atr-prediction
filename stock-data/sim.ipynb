{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a17c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lstm model\n",
    "import torch\n",
    "from torch.nn import *\n",
    "import torch.nn.functional as F\n",
    "from pandas_datareader import data as web\n",
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02690942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock(ticker, start_date, end_date, s_window, l_window):\n",
    "    try:\n",
    "        #yf.pdr_override()\n",
    "        df = yf.download(ticker, start=start_date, end=end_date,auto_adjust=False)\n",
    "        #print(\"DF: \",df)\n",
    "# can use this as well        df = web.get_data_yahoo(ticker, start=start_date, end=end_date)\n",
    "        df['Return'] = df['Adj Close'].pct_change()\n",
    "        df['Return'].fillna(0, inplace = True)\n",
    "        df['Date'] = df.index\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df['Month'] = df['Date'].dt.month\n",
    "        df['Year'] = df['Date'].dt.year \n",
    "        df['Day'] = df['Date'].dt.day\n",
    "        for col in ['Open', 'High', 'Low', 'Close', 'Adj Close']:\n",
    "            df[col] = df[col].round(2)\n",
    "        df['Weekday'] = df['Date'].dt.day_name()\n",
    "        df['Week_Number'] = df['Date'].dt.strftime('%U')\n",
    "        df['Year_Week'] = df['Date'].dt.strftime('%Y-%U')\n",
    "        df['Short_MA'] = df['Adj Close'].rolling(window=s_window, min_periods=1).mean()\n",
    "        df['Long_MA'] = df['Adj Close'].rolling(window=l_window, min_periods=1).mean()        \n",
    "        col_list = ['Date', 'Year', 'Month', 'Day', 'Weekday', \n",
    "                    'Week_Number', 'Year_Week', 'Open', \n",
    "                    'High', 'Low', 'Close', 'Volume', 'Adj Close',\n",
    "                    'Return', 'Short_MA', 'Long_MA']\n",
    "        num_lines = len(df)\n",
    "        df = df[col_list]\n",
    "        print('read ', num_lines, ' lines of data for ticker: ' , ticker)\n",
    "        return df\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a13e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split(df_n,vol_metric):\n",
    "    train = df_n.loc[[i<=len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_train = train[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_train = train[vol_metric].to_numpy()\n",
    "\n",
    "    test = df_n.loc[[i>len(df_n)*4/5 for i in range(len(df_n))]]\n",
    "    X_test = test[[\"index\",\"Open\",\"Close\",\"High\",\"Low\", vol_metric]].to_numpy()\n",
    "    y_test = test[vol_metric].to_numpy()\n",
    "    return X_train,y_train,X_test,y_test\n",
    "\n",
    "#X_train,y_train,X_test,y_test = tt_split(df_n,\"ATR_normalized\")\n",
    "\n",
    "#bollinger bands\n",
    "#try moving median instead of moving average\n",
    "#try moving quartiles instead of std; q3-q2  *1/2\n",
    "#take longer time period - five years\n",
    "\n",
    "#lstm,cnn,and rnn cant either predict directional volatiliy for xl stocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f21476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq(X_train,y_train,X_test,y_test):\n",
    "    T = 30  # sequence length (window size)\n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    X_seq_test = []\n",
    "    y_seq_test = []\n",
    "\n",
    "    for i in range(len(X_train) - T):\n",
    "        X_seq.append(X_train[i:i+T])  # shape: [T, 6] <- what is wanted in lstm\n",
    "        y_seq.append(y_train[i+T])    # predict next ATR value\n",
    "    for i in range(len(X_test)-T):    \n",
    "        X_seq_test.append(X_test[i:i+T])\n",
    "        y_seq_test.append(y_test[i+T])\n",
    "\n",
    "\n",
    "    X_seq = torch.tensor(X_seq, dtype=torch.float32)\n",
    "    y_seq = torch.tensor(y_seq, dtype=torch.float32).unsqueeze(1)\n",
    "    X_seq_test = torch.tensor(X_seq_test, dtype=torch.float32)\n",
    "    y_seq_test = torch.tensor(y_seq_test, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    return X_seq,y_seq,X_seq_test,y_seq_test\n",
    "#X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d68d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(X_seq,y_seq,X_seq_test,y_seq_test,batch_size=64):\n",
    "    dataset = TensorDataset(X_seq, y_seq)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    dataset_test = TensorDataset(X_seq_test,y_seq_test)\n",
    "    loader_test = DataLoader(dataset_test,batch_size=batch_size,shuffle=True)\n",
    "    return loader,loader_test\n",
    "#loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define lstm model\n",
    "\n",
    "class NN_LSTM(Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_size=input_size,hidden_size=30)\n",
    "        self.fc = Linear(30,output_size)\n",
    "    def activation(self,X):\n",
    "        return F.relu(X)\n",
    "    def forward(self,input):\n",
    "        input,_ = self.lstm(input)\n",
    "        input = self.fc(input[-1,:,:])\n",
    "        return input #return the last prediction\n",
    "#lstm_layer = LSTM(input_size=4,hidden_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74efcf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cleaned_df(ticker,start,end):\n",
    "    df = get_stock(ticker,start_date=start,end_date=end,s_window=14,l_window=50)\n",
    "    df_n= df.xs(ticker,axis=1,level=1)\n",
    "    \n",
    "        #define ATR columns\n",
    "    high = df_n[\"High\"]\n",
    "    low = df_n[\"Low\"]\n",
    "    close = df_n[\"Close\"]\n",
    "\n",
    "    prev_close = close.shift(1)\n",
    "\n",
    "\n",
    "    tr = pd.concat([\n",
    "        high - low,\n",
    "        (high - prev_close).abs(),\n",
    "        (low - prev_close).abs()\n",
    "    ], axis=1).max(axis=1)\n",
    "\n",
    "    df_n[\"ATR\"] = tr.rolling(7).mean()\n",
    "    \n",
    "    log_diff = np.log(df_n[\"Close\"]/df_n[\"Close\"].shift(1))\n",
    "    df_n[\"SD_Log_Close\"] = log_diff.rolling(7).std()\n",
    "    #df_n[\"ATR_normalized\"] = (df_n[\"ATR\"] - df_n[\"ATR\"].mean())/df_n[\"ATR\"].std()\n",
    "    #df_n[\"SD_normalized\"] = (df_n[\"SD_Log_Close\"] - df_n[\"SD_Log_Close\"].mean())/df_n[\"SD_Log_Close\"].std()\n",
    "\n",
    "    df_n = df_n.dropna()\n",
    "    df_n = df_n.reset_index().reset_index()\n",
    "    df_n[\"index\"] = df_n.index%7\n",
    "    return df_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a37eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trained_model(df,scaler):\n",
    "    metric = \"ATR\"\n",
    "    X_train,y_train,X_test,y_test = tt_split(df, metric,scaler)\n",
    "\n",
    "    X_seq,y_seq,X_seq_test,y_seq_test = make_seq(X_train,y_train,X_test,y_test)\n",
    "\n",
    "    loader,loader_test = create_loaders(X_seq,y_seq,X_seq_test,y_seq_test)\n",
    "\n",
    "    #training loop\n",
    "    \n",
    "    model = NN_LSTM(input_size=6,output_size=1)\n",
    "    epochs = 100\n",
    "    optim = torch.optim.Adam(params = model.parameters())\n",
    "    crit = MSELoss()\n",
    "    losses = []\n",
    "\n",
    "    for i in range(epochs):\n",
    "        running_loss = 0\n",
    "        for x_window,y_atr in loader:\n",
    "            #print(\"Running\")\n",
    "            input = x_window.permute(1,0,2) #shape = [seq_length,batch_length,4]\n",
    "            out = model(input)\n",
    "            #print(y_atr.shape)\n",
    "            #print(out,y_atr)\n",
    "            #break\n",
    "            loss = crit(out,y_atr)\n",
    "            running_loss+=loss.item()\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "                # could try loss += (i+1)/period/sum(j/period for j in range(period))crit(out,y_train[i]); adds a coeff to give more weigt to recent ones\n",
    "        #break\n",
    "        running_loss/=(len(loader))\n",
    "        #print(f\"Training Loss: {running_loss}\")\n",
    "        losses.append(running_loss)\n",
    "\n",
    "    sns.lineplot(x=[i for i in range(len(losses))],y=losses)\n",
    "    plt.title(f\"Training Loss of LSTM ({metric}) across 60 epochs for {ticker}\")\n",
    "    plt.show()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e99af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def backtest_atr_strategy(data: pd.DataFrame,\n",
    "                          lstm_model,\n",
    "                          scaler:StandardScaler,\n",
    "                          T: int = 30,\n",
    "                          R: float = 1000.0):\n",
    "    \"\"\"\n",
    "    Backtest a simple ATR‑based mean‑reversion strategy:\n",
    "      - Predict next ATR with an LSTM\n",
    "      - If predicted ATR is unusually high → go flat (sell)\n",
    "      - If unusually low → go long\n",
    "    Assumes 'data' has columns ['Open','High','Low','Close','ATR'].\n",
    "    'scaler' is a fitted StandardScaler on the train-period ATR.\n",
    "    \"\"\"\n",
    "    cash = 0.0\n",
    "    shares = 0.0\n",
    "\n",
    "    # Precompute rolling IQR thresholds on ATR over T bars\n",
    "    # (we’ll compute quantiles on‑the‑fly inside the loop)\n",
    "    for i in range(T, len(data)-1):\n",
    "        window_atr = data['ATR'].iloc[i-T:i]\n",
    "        q1 = window_atr.quantile(0.25)\n",
    "        q3 = window_atr.quantile(0.75)\n",
    "        med = window_atr.quantile(0.50)\n",
    "        iqr = q3 - q1\n",
    "        lower = med - 1.5 * iqr\n",
    "        upper = med + 1.5 * iqr\n",
    "\n",
    "        # Prepare model input: last T bars of OHLC + normalized ATR\n",
    "        X = data[['index','Open','High','Low','Close']].iloc[i-T:i].copy()\n",
    "        X['ATR_norm'] = scaler.transform(data[['ATR']].iloc[i-T:i])  # shape (T,1)\n",
    "        # reshape to (1, T, features)\n",
    "        print(X)\n",
    "        model_in = X.values.reshape(1, T, X.shape[1])\n",
    "        # Predict next normalized ATR, then denormalize\n",
    "        atr_next_norm = lstm_model(model_in).item()\n",
    "        atr_next = scaler.inverse_transform([[atr_next_norm]])[0,0]\n",
    "\n",
    "        # Next bar’s prices\n",
    "        open_next  = data['Open'].iloc[i+1]\n",
    "        close_next = data['Close'].iloc[i+1]\n",
    "\n",
    "        # Entry/exit signals\n",
    "        if atr_next > upper and shares > 0:\n",
    "            # Sell all\n",
    "            cash += shares * close_next\n",
    "            shares = 0.0\n",
    "\n",
    "        elif atr_next < lower:\n",
    "            # Buy: risk R = shares * ATR_next ⇒ shares = R / ATR_next\n",
    "            target_shares = R / atr_next\n",
    "            # adjust cash & position\n",
    "            delta = target_shares - shares\n",
    "            cash -= delta * open_next\n",
    "            shares = target_shares\n",
    "\n",
    "    # At end, mark-to-market at last close\n",
    "    final_value = cash + shares * data['Close'].iloc[-1]\n",
    "    return final_value, cash, shares\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e491d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'XPL'\n",
    "start = '2001-01-01'\n",
    "end = '2022-07-07'\n",
    "start_n = '2023-01-01'\n",
    "end_n = '2025-07-07'\n",
    "data = get_cleaned_df(ticker,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6052b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "model = get_trained_model(data,scaler = scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5602534",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = get_cleaned_df(ticker,start_n,end_n)\n",
    "final_value, money, shares = backtest_atr_strategy(data,model,scaler)\n",
    "print(final_value,money,shares)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
